Chapter 9: Adversarial Search
- Zero-sum games:
  • Agents have opposite utilities
  • Adversarial, pure competition
  • Minimax:
    - Time: O(b^m)
    - Space: O(bm)
    - Overall: space is pretty good, but time is problematic as most
      branching factors are going to be large (chess is b ~ 35, m ~ 100)
  • Resource limits (could you depth-limited search):
    - In realistic games, we cannot search to the leaves.
    - If we can search to the leaves, then we cannot evaluate the
      terminal states, and therefore need an evaluation function to
      determine the utility for that non-terminal state.
    - Guarantee of optimal play is gone.
    - The deeper you search in the tree, the less the quality of the
      evaluation function matters.
  • Evaluation function:
    - In practice, this is usually a weighted linear sum of features
    - Trashing is a problem that arises with poor evaluation function.
  • Pruning has no effect on minimax value computed for the root.
    - Time complexity drops to O(b^m/2)
    - Simple example of metareasoning
    
- Search overview:
  • Expectimax overview:
    - Deal with average-case now when outcomes are uncertain
    - Previously we dealt with worst-case in minimax, but that
      assumes outcomes are certain and the other adversary is playing
      optimally, which isn't always the case.
  • Hard to prune expectimax like we can do with minimax
    - This is because we could find 1M in the pruned children
  • Depth-limited expectimax
  • For worst-case minimax, the terminal evaluation scale doesn't matter
    as we want better states to have higher evaluations. The thing that
    does matter is the ordering of the states.
  • For average-case expectimax, the magnitudes need to be reasonable.
  • The dangers of optimism and pessimism:
    - Don't want to assume chance when the world is adversarial, and
      don't want to assume worst-case when that's not likely.
  • Expectiminimax tree:
    - Environment is where there's an extra player that moves after each
      min/max agent.

- Probability overview:
  • Random variable: represents a variable whose outcome is unknown.
  • Probability distribution: assignment of weights to outcomes.
  • Basic laws:
    - Probabilities cannot be negative.
    - Probabilities of one outcome sum to 1.

- Search for non zero-sum games:
  • Every agent acts to maximize their utility.
    - This means that some agents may work together in some situations
      in order to maximize their utility.
    - This cooperation or competition between the agents in the world
      is done dynamically.
  • Principle of maximum expected utility:
    - A rational agent should maximize its expected utility, given its
      knowledge.
      • This implies expectimax, and not minimax.
  • We hardwire utilities, and let behaviors emerge.
